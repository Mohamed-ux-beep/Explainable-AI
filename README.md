# Explainable Machine Learning with Decision Trees and Random Forests

Welcome to the **Explainable Machine Learning** project repository! This project demonstrates the application of **Decision Trees** and **Random Forests** to classify diabetes using the **Pima Indians Diabetes Dataset**. Additionally, it showcases the use of **LIME (Local Interpretable Model-Agnostic Explanations)** and **SHAP (SHapley Additive exPlanations)** to interpret the model predictions, ensuring transparency and accountability in machine learning models.

---

## üìã Project Overview

Machine learning models are often considered "black boxes" due to their complexity. This project focuses on interpreting and explaining model predictions using post-hoc techniques like LIME and SHAP to make them more understandable and trustworthy.

### Key Highlights:
- **Models Used**: Decision Tree and Random Forest
- **Dataset**: [Pima Indians Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database)
- **Explainability Techniques**: 
  - **LIME**: Local explanations for individual instances.
  - **SHAP**: Global feature importance and local contributions using Shapley values.
- **Metrics**: Model performance evaluation with **Accuracy** and analysis using **Confusion Matrices**.

---

## üöÄ Features
- Train and evaluate Decision Tree and Random Forest models.
- Visualize and analyze feature importance using SHAP and LIME.
- Understand local predictions for individual data points.
- Generate visual plots for:
  - Feature Importance
  - SHAP Summary and Dependence
  - LIME Explanations

---

## üõ†Ô∏è Technologies Used
- **Python**
  - `pandas`, `numpy`, `scikit-learn`
  - `matplotlib`, `seaborn`
  - `SHAP`, `lime`
- **Jupyter Notebooks** for visualization and experimentation.

---

